{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Vandanarajotiya/Dog_vision/blob/main/Dog_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!unzip \"drive/MyDrive/Dog Vision/dog-breed-identification.zip\" -d \"drive/MyDrive/Dog Vision/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"TF Hub version:\",hub.__version__)\n",
    "\n",
    "#check for GPU availability\n",
    "print(\"GPU\", \"available (YESSSSS!!!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available: (\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /content/sample_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lables_csv = pd.read_csv(\"drive/MyDrive/Dog Vision/labels.csv\")\n",
    "print(lables_csv.describe())\n",
    "print(lables_csv.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables_csv[\"breed\"].value_counts().plot.bar(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables_csv[\"breed\"].value_counts().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf \"drive/MyDrive/Dog Vision/train\"\n",
    "# !unzip \"drive/MyDrive/Dog Vision/train.zip\" -d \"drive/MyDrive/Dog Vision/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"drive/MyDrive/Dog Vision/train/001513dfcb2ffafc82cccf4d8bbaba97.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = [\"drive/MyDrive/Dog Vision/train/\" + fname + \".jpg\" for fname in lables_csv[\"id\"]]\n",
    "filename[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if len(os.listdir(\"drive/MyDrive/Dog Vision/train/\")) == len(filename):\n",
    "  print(\"Filenames match actual amount of files!!! \")\n",
    "else:\n",
    "  print(\"Filename do no match actual amount of filels , check the traget directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename[9000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lables = lables_csv[\"breed\"].to_numpy()\n",
    "lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(lables) == len(filename):\n",
    "  print(\"number of lables matches number of filenames\")\n",
    "else:\n",
    "  print(\"number of lables do not match number of filenames. check data directoris!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the unique\n",
    "unique_breeds = np.unique(lables)\n",
    "len(unique_breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_lables = [lables == unique_breeds for lables in lables]\n",
    "boolean_lables[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES = 1000 #@param {type: \"slider\" , min:1000,max:10000 , step:1000}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X,y= filename , boolean_lables\n",
    "X_train, X_val ,y_train , y_val = train_test_split(X[:NUM_IMAGES],\n",
    "                                                   y[:NUM_IMAGES],\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42)\n",
    "\n",
    "len(X_train),len(y_train),len(X_val),len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:5] , y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert image to numpy array\n",
    "from matplotlib.pyplot import imread\n",
    "image = imread(filename[42])\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(image)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE= 224\n",
    "\n",
    "def process_image(image_path , img_size = IMG_SIZE):\n",
    "  \"\"\"\n",
    "  Takes an image file path and turns it into a Tensor.\n",
    "  \"\"\"\n",
    "  # Read in an image file\n",
    "  image = tf.io.read_file(image_path)\n",
    "  #Turn the jpeg image to numerical Tensor with 3 color channels\n",
    "  image = tf.io.decode_jpeg(image,channels=3)\n",
    "  # Convert the colour chennel values from 0-255 to 0-1 values\n",
    "  image = tf.image.convert_image_dtype(image , tf.float32)\n",
    "  # Resize the image to our desired value (224 , 224)\n",
    "  image = tf.image.resize(image,size=[IMG_SIZE,IMG_SIZE])\n",
    "\n",
    "  return image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning our data into batches\n",
    "def get_image_lable(image_path , lable):\n",
    "  \"\"\"\n",
    "  Taken an image file path name and the associated lable,\n",
    "  processes the image and returns a lable type of (image, lable)\n",
    "  \"\"\"\n",
    "  image = process_image(image_path)\n",
    "  return image, lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_image(X[42], y[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "# crete a function to turn data into batches\n",
    "def create_data_batches(X,y=None,batch_size=BATCH_SIZE,valid_data=False,test_data=False):\n",
    "  \"\"\"\n",
    "  create batches of data out of image (x)and lable (y)\n",
    "  suffles the data if it's traning data but doesn't shuffle if it's validation data\n",
    "  also accepts test data as input (no lables)\n",
    "  \"\"\"\n",
    "  if test_data:\n",
    "    print(\"Creating test data batches\")\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X)))\n",
    "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
    "    return data_batch\n",
    "# if the data is a valid dataset , we don't need shuffle it\n",
    "  elif valid_data:\n",
    "    print(\"Creating validation data batches....\")\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X),\n",
    "                                               tf.constant(y)))\n",
    "    data_batch = data.map(get_image_lable).batch(BATCH_SIZE)\n",
    "    return data_batch\n",
    "\n",
    "  else:\n",
    "    print(\"Creating training data batches....\")\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X),\n",
    "                                               tf.constant(y)))\n",
    "    data = data.shuffle(buffer_size=len(X))\n",
    "    data = data.map(get_image_lable)\n",
    "\n",
    "    #turn the traning data into batchs\n",
    "    data_batch = data.batch(BATCH_SIZE)\n",
    "  return data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = create_data_batches(X_train,y_train)\n",
    "valid_data = create_data_batches(X_val,y_val,valid_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different attributes of out data batches\n",
    "train_data.element_spec , valid_data.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omWYQ8tgjZ_y"
   },
   "source": [
    "Training → shuffle + preprocess + batch\n",
    "Validation → preprocess + batch (no shuffle)\n",
    "Test → preprocess + batch (sirf images, no labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Ceate a function for viewing images in a data batch\n",
    "def show_25_images(images,lables):\n",
    "  \"\"\"\n",
    "  displays 25 images from a data batch\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10,10))\n",
    "  for i in range(25):\n",
    "    ax = plt.subplot(5,5,i+1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(unique_breeds[lables[i].argmax()])\n",
    "    # grid lines off\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images , train_lables = next(train_data.as_numpy_iterator())\n",
    "show_25_images(train_images, train_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images , val_lables = next(valid_data.as_numpy_iterator())\n",
    "show_25_images(val_images,val_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = len(unique_breeds)  \n",
    "\n",
    "def create_model():\n",
    "    base_model = MobileNetV2(\n",
    "        include_top=False,         \n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),          \n",
    "        weights='imagenet'         \n",
    "    )\n",
    "    base_model.trainable = False \n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=base_model.input,outputs = output)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lode tenserboard notebook extention\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def create_tensorboard_callback():\n",
    "  logdir = os.path.join(\"drive/MyDrive/Dog Vision/logs\",\n",
    "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  return tf.keras.callbacks.TensorBoard(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_accuracy\",\n",
    "                                                  patience = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMFh9gid7sTE"
   },
   "source": [
    "Training a Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100 #@param {type: \"slider\" , min:10 , max:100 , step:10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU\" , \"available (YESSSS!!!!!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available (\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a function to train and return trained model\n",
    "def train_model():\n",
    "  \"\"\"\n",
    "  Train aa givin model and return a trained version\n",
    "  \"\"\"\n",
    "  #create a model\n",
    "  model = create_model()\n",
    "  #Create a Tensorboard session evertime train a model\n",
    "  TensorBoard =  create_tensorboard_callback()\n",
    "\n",
    "  #fit the model to the data passing it the callback we created\n",
    "  model.fit(x=train_data,\n",
    "            epochs = NUM_EPOCHS,\n",
    "            validation_data = valid_data,\n",
    "            validation_freq = 1,\n",
    "            callbacks = [TensorBoard , early_stopping])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making and Evaluationg predictions using a traind model\n",
    "prediction = model.predict(valid_data , verbose=1)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Prediction\n",
    "index = 0\n",
    "print(f\"max value (probability of predication): {np.max(prediction[index])}\")\n",
    "print(f\"Sum :{np.sum(prediction[index])}\")\n",
    "print(f\"Max index : {np.argmax(prediction[index])}\")\n",
    "print(f\"Prediction :{unique_breeds[np.argmax(prediction[index])]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn prediction probabilities into their respactive lables\n",
    "def get_pred_lable(prediction_probabilities):\n",
    "  \"\"\"\n",
    "  Turn an array predictions probabilities into lables\n",
    "  \"\"\"\n",
    "  return unique_breeds[np.argmax(prediction_probabilities)]\n",
    "\n",
    "# get a prediction lable based on an array on prediction probabilities\n",
    "pred_lable = get_pred_lable(prediction[9])\n",
    "pred_lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function unbatch abatch dataset\n",
    "def unbatchify(data):\n",
    "  \"\"\"\n",
    "  Takes a batch dataset of (image.lables) Tensors and returns separate arrays\n",
    "  of images and lables\n",
    "  \"\"\"\n",
    "  images = []\n",
    "  lables = []\n",
    "\n",
    "  for image , lable in data.unbatch().as_numpy_iterator():\n",
    "    images.append(image)\n",
    "    lables.append(unique_breeds[np.argmax(lable)])\n",
    "  return images, lables\n",
    "\n",
    "\n",
    "val_images , val_lables = unbatchify(valid_data)\n",
    "val_images[0],val_lables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred_lable(val_lables[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred(prediction_probabilities , lables , images , n=1):\n",
    "  \"\"\"\n",
    "  View the prediction, ground truth and image and semple\n",
    "  \"\"\"\n",
    "  pred_prob, true_lable , image = prediction_probabilities[n] , lables[n],images[n]\n",
    "\n",
    "  pred_lable = get_pred_lable(pred_prob)\n",
    "  plt.imshow(image)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.title(\"{} {:2.0f}% {}\".format(pred_lable ,\n",
    "                                      np.max(pred_prob)*100,\n",
    "                                      true_lable ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred(prediction_probabilities = prediction,\n",
    "          lables = val_lables,\n",
    "          images = val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred(prediction_probabilities = prediction,\n",
    "          lables = val_lables,\n",
    "          images = val_images,\n",
    "          n=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_conf(prediction_probabilities, labels, n=1):\n",
    "    \"\"\"\n",
    "    Plots top 10 highest prediction confidences along with the truth label for sample n\n",
    "    \"\"\"\n",
    "    pred_prob, true_label = prediction_probabilities[n], labels[n]\n",
    "    pred_label = get_pred_lable(pred_prob)\n",
    "    top_10_pred_index = pred_prob.argsort()[-10:][::-1]\n",
    "    top_10_pred_value = pred_prob[top_10_pred_index]\n",
    "    top_10_pred_labels = unique_breeds[top_10_pred_index]\n",
    "\n",
    "    top_plot = plt.bar(np.arange(len(top_10_pred_labels)),\n",
    "                       top_10_pred_value,\n",
    "                       color=\"gray\")\n",
    "\n",
    "    plt.xticks(np.arange(len(top_10_pred_labels)),\n",
    "               labels=top_10_pred_labels,\n",
    "               rotation=\"vertical\")\n",
    "\n",
    "    if np.isin(true_label, top_10_pred_labels):\n",
    "        top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"green\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_conf(prediction_probabilities=prediction,\n",
    "               labels = val_lables,\n",
    "               n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_multiplier = 0\n",
    "num_cols = 2\n",
    "num_rows = 3\n",
    "num_images = num_cols*num_rows\n",
    "plt.figure(figsize=(10*num_cols , 5*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows,2*num_cols, 2*i+1)\n",
    "  plot_pred(prediction_probabilities=prediction,\n",
    "            lables = val_lables,\n",
    "            images=val_images,\n",
    "            n = i+i_multiplier)\n",
    "  plt.subplot(num_rows,2*num_cols, 2*i+2)\n",
    "  plot_pred_conf(prediction_probabilities=prediction,\n",
    "            labels = val_lables,\n",
    "            n=i+i_multiplier)\n",
    "plt.tight_layout(h_pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-keras-vis\n",
    "\n",
    "from tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=99\n",
    "img = val_images[n]\n",
    "img_batch = np.expand_dims(img, axis=0)\n",
    "pred=model.predict(img_batch)\n",
    "target_class_index = np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def show_gradcam(model,val_images,n):\n",
    "  img = val_images[n]\n",
    "  img_batch = np.expand_dims(img, axis=0)\n",
    "  pred=model.predict(img_batch)\n",
    "  target_class_index = np.argmax(pred[0])\n",
    "\n",
    "  heatmap = GradcamPlusPlus(model, model_modifier=ReplaceToLinear(), clone=True)(\n",
    "    CategoricalScore(target_class_index), img_batch)[0]\n",
    "\n",
    "  # Normalize\n",
    "  heatmap = np.maximum(heatmap, 0)\n",
    "  heatmap = heatmap / (heatmap.max() + 1e-8)\n",
    "\n",
    "  # Resize to match original\n",
    "  heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "  # Threshold (makes output SUPER CLEAR)\n",
    "  heatmap[heatmap < 0.7] = 0\n",
    "\n",
    "  # Color map\n",
    "  heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "  # Soft overlay\n",
    "  overlay = cv2.addWeighted(np.uint8(img * 255), 0.8, heatmap_color, 0.2, 0)\n",
    "\n",
    "  plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "  return target_class_index, pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gradcam(model,val_images,n=59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, suffix=\"model\"):\n",
    "    \"\"\"\n",
    "    Saves a given model in a models directory and appends a suffix (string).\n",
    "    \"\"\"\n",
    "    # Create directory path\n",
    "    model_dir = os.path.join(\"drive/MyDrive/Dog Vision/models\",\n",
    "                             datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    os.makedirs(model_dir, exist_ok=True)  # ensure directory exists\n",
    "\n",
    "    # Full path for the model file\n",
    "    model_path = os.path.join(model_dir, f\"{suffix}.h5\")\n",
    "    print(f\"Saving model to {model_path}....\")\n",
    "    model.save(model_path)\n",
    "\n",
    "    return model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model to lode a trained model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading saved model from: {model_path}\")\n",
    "    return tf.keras.models.load_model(model_path)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our model trained on 1000 images\n",
    "save_model(model, suffix=\"1000-images-Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_hub as hub  \n",
    "\n",
    "loaded_model = load_model(\n",
    "    \"drive/MyDrive/Dog Vision/models/20251013-055120/1000-images-Adam.h5\",\n",
    "    custom_objects={\"KerasLayer\": hub.KerasLayer} \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.evaluate(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = create_data_batches(X,y)\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_tensorboard = create_tensorboard_callback()\n",
    "\n",
    "# no validation setwhen traning all the data , so we can't monitar validation accuracy\n",
    "full_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n",
    "                                                             patience = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(\n",
    "        img.astype('double'),\n",
    "        model.predict,\n",
    "        top_labels=5,\n",
    "        hide_color=0,\n",
    "        num_samples=1000)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(\n",
    "        label=explanation.top_labels[0],\n",
    "        positive_only=True,\n",
    "        hide_rest=False)\n",
    "\n",
    "plt.imshow(mark_boundaries(temp / 255.0, mask))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the full model to the full data\n",
    "full_model.fit(x=full_data,\n",
    "               epochs=NUM_EPOCHS,\n",
    "               callbacks=[full_model_tensorboard, full_model_early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(full_model, suffix=\"full-image-set-mobilenetv2-Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the full model\n",
    "loaded_full_model = load_model(\"drive/MyDrive/Dog Vision/models/20251013-065358/full-image-set-mobilenetv2-Adam.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test image filenames\n",
    "test_path = \"drive/MyDrive/Dog Vision/test/test/\"\n",
    "test_filenames = [test_path + fname for fname in os.listdir(test_path)]\n",
    "test_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def create_data_batches(image_paths, batch_size=32, test_data=False):\n",
    "    # Keep only files\n",
    "    image_paths = [p for p in image_paths if os.path.isfile(p)]\n",
    "\n",
    "    def preprocess(path):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [224, 224])\n",
    "        img = img / 255.0\n",
    "        return img\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = create_data_batches(test_filenames, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = loaded_full_model.predict(test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas DataFrame with empty columns\n",
    "preds_df = pd.DataFrame(columns=[\"id\"] + list(unique_breeds))\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path =  \"drive/MyDrive/Dog Vision/test/test/\"\n",
    "preds_df[\"id\"] = [os.path.splitext(path)[0] for path in os.listdir(test_path)]\n",
    "preds_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[list(unique_breeds)] = test_predictions\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our predictions dataframe to CSV for submission to Kaggle\n",
    "preds_df.to_csv(\"drive/MyDrive/Dog Vision/full_model_predictions_submission_1_mobilenetV2.csv\",\n",
    "                index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_path = \"drive/MyDrive/Dog Vision/dogs/\"\n",
    "custom_image_paths = [custom_path + fname for fname in os.listdir(custom_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_data = create_data_batches(custom_image_paths, test_data=True)\n",
    "custom_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_preds = loaded_full_model.predict(custom_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pred_labels = [get_pred_lable(custom_preds[i]) for i in range(len(custom_preds))]\n",
    "custom_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_images = [img for img in custom_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "custom_images = np.array(custom_images)\n",
    "\n",
    "num_to_show = min(4, len(custom_images))\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "for i in range(num_to_show):\n",
    "    plt.subplot(1, num_to_show, i+1)\n",
    "    plt.axis('off')\n",
    "\n",
    "    img = custom_images[i]\n",
    "\n",
    "    if img.ndim == 4:\n",
    "        img = img[0]\n",
    "    if img.max() <= 1.0:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    else:\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title(custom_pred_labels[i] if i < len(custom_pred_labels) else \"N/A\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
